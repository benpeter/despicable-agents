---
name: nefario
description: >
  Orchestrate a team of specialist agents for complex, multi-domain tasks.
  Uses a nine-phase process: nefario creates a meta-plan, specialists
  contribute domain expertise, nefario synthesizes, cross-cutting agents
  review the plan, you execute, then post-execution phases verify code
  quality, run tests, optionally deploy, and update documentation.
argument-hint: "<task description>"
---

# Nefario Orchestrator

You are executing the Nefario orchestration workflow. This skill coordinates
a multi-phase planning process that leverages specialist domain expertise
before execution.

## Core Rules

You ALWAYS follow the full workflow described above. You NEVER skip any phase based on your own judgement, EVEN if it appears to be only a single-file or simple thing, EVEN if it violates YAGNI or KISS. There are NO exceptions to this, only the user can override this.
You NEVER skip any gates or approval steps based on your own judgement, EVEN if it appears to be only a single-file or simple thing, EVEN if it violates YAGNI or KISS. There are NO exceptions to this, only the user can override this.

## Overview

The workflow has nine phases:

1. **Meta-plan** — Nefario identifies which specialists to consult
2. **Specialist planning** — Domain experts contribute their perspective
3. **Synthesis** — Nefario consolidates into an execution plan
3.5. **Architecture Review** — Cross-cutting agents review before execution
4. **Execution** — You spawn agents and coordinate the work
5. **Code Review** — Parallel review of agent-produced code (conditional: code produced)
6. **Test Execution** — Run and validate tests (conditional: tests exist)
7. **Deployment** — Run deployment commands (conditional: user-requested)
8. **Documentation** — Generate/update project documentation (conditional: checklist has items)

## Communication Protocol

The orchestrator MUST minimize chat output. The user should only see:

**SHOW** (these are the only things printed to chat):
- Approval gate decision briefs (full structured format)
- PR creation prompt
- Final summary (report path, PR URL, branch name)
- Warnings and errors
- Compaction checkpoints (at phase boundaries)
- Unresolvable BLOCK escalation from post-execution phases (after 2-round cap)
- Security-severity BLOCK escalation (before auto-fix, max 5 lines)

**NEVER SHOW** (suppress entirely):
- Phase transition announcements ("Starting Phase 2...")
- Echoing prompts being sent to subagents
- Agent spawning narration ("Spawning security-minion...")
- Task status polling output
- Agent completion acknowledgments
- Review verdicts (unless BLOCK)
- Post-execution phase transitions ("Starting code review...", "Running tests...")
- Post-execution reviewer spawning and auto-fix iterations

**CONDENSE** to a single line:
- Meta-plan result: "Planning: consulting devx-minion, security-minion, ..."
- Review verdicts (if no BLOCK): "Review: 4 APPROVE, 0 BLOCK"
- ADVISE notes: fold silently into relevant task prompts, do not print
- Post-execution start: "Verifying: code review, tests, documentation..."
- Post-execution result: fold into wrap-up ("Verification: all checks passed" or "Verification: 2 findings auto-fixed, all tests pass, docs updated")

Heartbeat: for phases lasting more than 60 seconds with no output, print a
single status line (e.g., "Waiting for 3 agents...") to confirm progress.

## Scratch File Convention

Phase outputs are written to scratch files to prevent context accumulation.
The main session retains compact summaries; full outputs live on disk.

### Directory Structure

Each orchestration session uses a subdirectory under `nefario/scratch/`:

```
nefario/scratch/{slug}/
  phase1-metaplan.md
  phase2-{agent-name}.md        # one per specialist
  phase3-synthesis.md
  phase3.5-{reviewer-name}.md   # one per reviewer (BLOCK/ADVISE only)
  phase5-code-review-minion.md  # BLOCK/ADVISE only
  phase5-lucy.md                # BLOCK/ADVISE only
  phase5-margo.md               # BLOCK/ADVISE only
  phase6-test-results.md
  phase7-deployment.md          # if Phase 7 ran
  phase8-checklist.md           # generated by nefario
  phase8-software-docs.md       # if Phase 8 ran
  phase8-user-docs.md           # if Phase 8 ran
  phase8-marketing-review.md    # if sub-step 8b ran
```

The `{slug}` reuses the report slug generated in Phase 1 (kebab-case, lowercase,
max 40 chars, strip articles, alphanumeric and hyphens only). Create the directory
with `mkdir -p` at the start of Phase 1.

### Inline Summary Template

After writing a specialist's full output to a scratch file, record a compact
summary in the session context:

```
## Summary: {agent-name}
Phase: {planning | review}
Recommendation: {1-2 sentences}
Tasks: {N} -- {one-line each, semicolons}
Risks: {critical only, 1-2 bullets}
Conflicts: {cross-domain conflicts, or "none"}
Verdict: {APPROVE | ADVISE(details) | BLOCK(details)} (Phase 3.5 reviewers only)
Full output: nefario/scratch/{slug}/phase2-{agent-name}.md
```

The `Phase` field groups agents in the report's Agent Contributions section.
Planning agents (Phase 2) get `Phase: planning`. Architecture reviewers
(Phase 3.5) get `Phase: review`.

Each summary: ~80-120 tokens (~100-150 for reviewers, verdict field adds ~20 tokens).
Versus 500-2000+ for full contributions.

### Lifecycle

- **Creation**: `mkdir -p nefario/scratch/{slug}/` at Phase 1 start.
- **Overwrites**: If the same slug directory exists, overwrite silently (retry).
- **Cleanup**: Never auto-delete. Scratch files persist for debugging.
  Manual cleanup: `rm -rf nefario/scratch/*/`
- **Git**: `nefario/scratch/` is gitignored (except `.gitkeep`).

## Phase 1: Meta-Plan

**Before spawning nefario**: Generate the session slug from the task description
(same rules as report slug: kebab-case, lowercase, max 40 chars, strip articles,
alphanumeric and hyphens only). Create the scratch directory:
`mkdir -p nefario/scratch/{slug}/`.

Capture the verbatim user task description (the text that will be inserted at
`<insert the user's task description>`) and retain it in session context as
`original-prompt`. This is the text that appears in the report's Task section.
Before including in the report, sanitize: remove any secrets, tokens, API keys,
or credentials. Replace with `[REDACTED]`.

Spawn nefario as a planning subagent to analyze the task and determine
which specialists should be consulted for planning.

```
Task:
  subagent_type: nefario
  description: "Create meta-plan"
  model: opus
  prompt: |
    MODE: META-PLAN

    You are creating a meta-plan — a plan for who should help plan.

    ## Task
    <insert the user's task description>

    ## Working Directory
    <insert cwd>

    ## Instructions
    1. Read relevant files to understand the codebase context
    2. Analyze the task against your delegation table
    3. Identify which specialists should be CONSULTED FOR PLANNING
       (not execution — planning). These are agents whose domain
       expertise is needed to create a good plan.
    4. For each specialist, write a specific planning question that
       draws on their unique expertise.
    5. Return the meta-plan in the structured format.
    6. Write your complete meta-plan to `nefario/scratch/{slug}/phase1-metaplan.md`
```

Nefario will return a meta-plan listing which specialists to consult
and what to ask each one. Review it briefly — if it looks reasonable,
proceed to Phase 2. No need for formal user approval at this stage.

## Phase 2: Specialist Planning

For each specialist in the meta-plan, spawn them as a subagent **in parallel**.
Each specialist gets:
- The original task description
- Their specific planning question from nefario
- Relevant codebase context
- Instructions to return a domain plan contribution

```
Task:
  subagent_type: <agent-name from meta-plan>
  description: "<agent> planning input"
  model: opus  # planning = opus
  prompt: |
    You are contributing to the PLANNING phase of a multi-agent project.
    You are NOT executing yet — you are providing your domain expertise
    to help build a comprehensive plan.

    ## Project Task
    <insert the user's original task>

    ## Your Planning Question
    <insert the specific question from nefario's meta-plan>

    ## Context
    <insert any relevant codebase context from nefario's meta-plan>

    ## Instructions
    1. Read relevant files to understand the current state
    2. Apply your domain expertise to the planning question
    3. Identify risks, dependencies, and requirements from your perspective
    4. If you believe additional specialists should be involved that
       aren't already part of the planning, say so and explain why
    5. Return your contribution in this format:

    ## Domain Plan Contribution: <your-name>

    ### Recommendations
    <your expert recommendations for this aspect of the task>

    ### Proposed Tasks
    <specific tasks that should be in the execution plan>
    For each task: what to do, deliverables, dependencies

    ### Risks and Concerns
    <things that could go wrong from your domain perspective>

    ### Additional Agents Needed
    <any specialists not yet involved who should be, and why>
    (or "None" if the current team is sufficient)
    6. Write your complete contribution to `nefario/scratch/{slug}/phase2-{your-name}.md`
```

**After each specialist returns**: Write their full output to the scratch file
(if the specialist did not already do so). Record an inline summary using the
template from the Scratch File Convention section. Pass only the summary and
file path forward -- do not paste the full contribution into later prompts.

**Important**: If any specialist recommends additional agents, spawn those
agents for planning too (a second round of Phase 2 consultations), then
include their contributions in Phase 3.

## Phase 3: Synthesis

Spawn nefario again with ALL specialist contributions to create the
final execution plan.

```
Task:
  subagent_type: nefario
  description: "Synthesize execution plan"
  model: opus
  prompt: |
    MODE: SYNTHESIS

    You are synthesizing specialist planning contributions into a
    final execution plan.

    ## Original Task
    <insert the user's task>

    ## Specialist Contributions

    Read the following scratch files for full specialist contributions:
    <list each file path: nefario/scratch/{slug}/phase2-{agent}.md>

    ## Key consensus across specialists:
    <paste the inline summaries collected during Phase 2>

    ## Instructions
    1. Review all specialist contributions
    2. Resolve any conflicts between recommendations
    3. Incorporate risks and concerns into the plan
    4. Create the final execution plan in structured format
    5. Ensure every task has a complete, self-contained prompt
    6. Write your complete delegation plan to `nefario/scratch/{slug}/phase3-synthesis.md`
```

Nefario will return a structured delegation plan. **After synthesis returns**:
Write the full execution plan to `nefario/scratch/{slug}/phase3-synthesis.md`
(if nefario did not already do so). Record a compact summary (task count, gate
count, execution order) in session context. **Proceed to Phase 3.5
(Architecture Review)** before presenting the plan to the user.

### Compaction Checkpoint

After writing the synthesis to the scratch file, present a compaction prompt:

```
---
COMPACT: Phase 3 complete. Specialist details are now in the synthesis.

Run: /compact focus="Preserve: current phase (3.5 review next), synthesized execution plan, inline agent summaries, task list, approval gates, team name, branch name, scratch directory path. Discard: individual specialist contributions from Phase 2."

After compaction, type `continue` to resume at Phase 3.5 (Architecture Review).

Skipping is fine if context is short. Risk: auto-compaction in later phases may lose orchestration state.
---
```

If the user runs `/compact`, wait for them to say "continue" then proceed.
If the user types anything else (or says "skip"/"continue"), print:
`Continuing without compaction. Auto-compaction may interrupt later phases.`
Then proceed to Phase 3.5. Do NOT re-prompt at subsequent boundaries.

## Phase 3.5: Architecture Review

After nefario returns the delegation plan from synthesis, run a cross-cutting
review before presenting to the user.

### Identify Reviewers

From the delegation plan, determine which cross-cutting agents should review:
- **Always** (mandatory reviewers):
  - security-minion
  - test-minion
  - ux-strategy-minion
  - software-docs-minion
  - lucy
  - margo
- **Conditional**:
  - observability-minion: 2+ tasks produce runtime components, services, or APIs
  - ux-design-minion: 1+ tasks produce user-facing interfaces
  - accessibility-minion: 1+ tasks produce web-facing UI
  - sitespeed-minion: 1+ tasks produce web-facing runtime components

### Spawn Reviewers

Spawn all identified reviewers in parallel. Use opus for lucy and margo
(governance reviewers requiring deeper reasoning); use sonnet for all others:

```
Task:
  subagent_type: <reviewer agent>
  description: "<agent> architecture review"
  model: opus  # for lucy, margo; sonnet for all other reviewers
  prompt: |
    You are reviewing a delegation plan before execution begins.
    Your role: identify gaps, risks, or concerns from your domain.

    ## Delegation Plan
    Read the full plan from: nefario/scratch/{slug}/phase3-synthesis.md

    ## Your Review Focus
    <domain-specific: security gaps / test coverage / observability gaps / etc.>

    ## Instructions
    Return exactly one verdict:
    - APPROVE: No concerns from your domain.
    - ADVISE: <list specific non-blocking warnings>
    - BLOCK: <describe the blocking issue and what must change>

    Be concise. Only flag issues within your domain expertise.
```

### Process Verdicts

- **All APPROVE or ADVISE**: Append any ADVISE notes to the relevant task
  prompts. Present the plan to the user for approval. Proceed to Phase 4.
- **Any BLOCK**: Send the BLOCK feedback back to nefario (MODE: SYNTHESIS)
  to revise the plan. Then re-submit the revised plan to the blocking
  reviewer only. Cap at 2 revision rounds. If still blocked after 2 rounds,
  present the impasse to the user for decision.

**After all reviews complete**: Write any BLOCK or ADVISE verdicts to
`nefario/scratch/{slug}/phase3.5-{reviewer}.md`. APPROVE verdicts do not
need scratch files.

### Compaction Checkpoint

After processing all review verdicts, present a compaction prompt:

```
---
COMPACT: Phase 3.5 complete. Review verdicts are folded into the plan.

Run: /compact focus="Preserve: current phase (4 execution next), final execution plan with ADVISE notes incorporated, inline agent summaries, gate decision briefs, task list with dependencies, approval gates, team name, branch name, scratch directory path. Discard: individual review verdicts, Phase 2 specialist contributions, raw synthesis input."

After compaction, type `continue` to resume at Phase 4 (Execution).

Skipping is fine if context is short. Risk: auto-compaction during execution may lose task/agent tracking.
---
```

Same response handling: if user runs `/compact`, wait for "continue". If
anything else, print the continuation message and proceed. Do NOT re-prompt.

## Phase 4: Execution

After user approval, execute the plan. If the plan contains **approval gates**,
execution proceeds in batches separated by gate checkpoints.

### Branch Creation

Before spawning any execution agents, isolate work on a feature branch.

1. Get current branch: `git branch --show-current`
2. If already on a non-main feature branch, use it (do not create a nested
   branch, do not switch to main).
3. If on `main` or `master`:
   a. Check working tree: `git status --porcelain`
   b. If dirty, warn: "Working tree has uncommitted changes. Stash or commit
      before proceeding." and STOP.
   c. Pull latest: `git pull --rebase`
   d. If pull fails, warn and STOP.
   e. Create feature branch: `git checkout -b nefario/<slug>` (reuse the slug
      generated in Phase 1).

### Setup

1. **Create a team** using TeamCreate with the team name from the plan.

2. **Create tasks** using TaskCreate for each task in the plan.
   Set dependencies via TaskUpdate.

### Execution Loop

Group tasks into batches based on dependencies and approval gates.
A batch contains all tasks that can run before the next gate.

3. **Spawn teammates** for the current batch using the Task tool:
   ```
   Task:
     subagent_type: <agent name>
     description: <short summary>
     model: <from plan — usually sonnet for execution>
     mode: <from plan>
     team_name: <team name>
     name: <agent name>
     prompt: <prompt from plan>
   ```
   Spawn independent tasks in parallel. In each agent's prompt, include
   this instruction at the end:

   > When you finish your task, mark it completed with TaskUpdate and
   > send a message to the team lead summarizing what you produced and
   > where the deliverables are. Include file paths.

4. **Actively monitor completion.** After spawning agents, DO NOT just
   wait passively. You are the orchestrator — you must drive progress:

   - After spawning, immediately call `TaskList` to show current status.
   - When you receive a message from a teammate (delivered as a new turn),
     acknowledge it, call `TaskList` to check overall progress, and decide
     what to do next (spawn next batch, present gate deliverable, etc.).
   - When a teammate goes idle, check `TaskList`. If their task is marked
     completed, proceed. If not, send them a message asking for status.
   - **When ALL tasks in the current batch are complete**, immediately
     proceed to the next step (next batch, gate checkpoint, or wrap-up).
     Do not wait for the user to tell you to continue.
   - If you're unsure whether an agent is done, call `TaskList` and check
     task status. Trust the task status over idle notifications.

5. **At approval gates**: When a gated task completes, present its
   deliverable using the structured decision brief:

   ```
   APPROVAL GATE: <Task title>
   Agent: <who produced this> | Blocked tasks: <what's waiting>

   DECISION: <one-sentence summary of the deliverable/decision>

   RATIONALE:
   - <key point 1>
   - <key point 2>
   - <rejected alternative and why>

   IMPACT: <what approving/rejecting means for the project>
   DELIVERABLE: <file path(s) to review>
   Confidence: HIGH | MEDIUM | LOW
   Post-execution: code review + tests + docs (skip with "approve --skip-post")

   Reply: approve / request changes / reject / skip
   ```

   Response handling:
   - **approve**: Auto-commit changes (see below), then continue to next
     batch. After execution, run post-execution phases (5-8).
   - **approve --skip-post**: Auto-commit, then skip Phases 5, 6, 8.
     Phase 7 is already opt-in and unaffected.
   - **request changes**: Send feedback to the agent for revision.
     Cap at 2 revision rounds. After 2 rounds, ask the user for more
     detailed direction.
   - **reject**: Confirm with the user -- show which dependent tasks will
     also be dropped. Then remove from plan and continue.
   - **skip**: Defer the gate. Continue with non-blocked tasks.
     Re-present skipped gates before the wrap-up phase.

   **Auto-commit after gate approval**: After a gate is approved, silently:
   1. Identify files changed since the last commit (use the change ledger).
   2. Filter against sensitive patterns (existing safety rails apply).
   3. If no changes or all changes are sensitive, skip silently.
   4. Stage and commit with conventional commit message:
      `<type>(<scope>): <summary>` with
      `Co-Authored-By: Claude <noreply@anthropic.com>`
   5. Print ONE informational line:
      `Committed N files: path1, path2, ...`
      (list up to 5 files; if more, show first 4 and "+ N more").
   6. If commit fails, print a warning and continue (do not block execution).

   Never use `git add -A` — only stage files from the change ledger.
   See [docs/commit-workflow.md](../docs/commit-workflow.md) for the
   full protocol (sensitive file filtering, safety rails, edge cases).

   Anti-fatigue guidelines:
   - Budget 3-5 approval gates per plan. If synthesis produces more,
     consolidate related gates.
   - Include rejected alternatives in every brief -- this is the key lever
     against rubber-stamping.
   - Set confidence based on: number of viable alternatives (more = lower),
     reversibility (harder = lower), downstream dependents (more = lower).
   - Calibration check: After 5 consecutive approvals without changes, present:
     "You have approved the last 5 gates without changes. Are the gates
     well-calibrated, or should future plans gate fewer decisions?"

6. Repeat steps 3-5 for each batch until all tasks are complete.

### Post-Execution Phases (5-8)

After all execution batches complete, run post-execution verification.
These phases follow the **dark kitchen** pattern: they run silently. The
user sees one CONDENSE line at the start and one consolidated result in
the wrap-up summary.

Print: `Verifying: code review, tests, documentation...`

If the user said `approve --skip-post`, skip to Wrap-up.

**Optional compaction**: If context pressure is high after Phase 4,
consider a compaction checkpoint here. Not mandatory -- it breaks the
dark kitchen silence. Note as future optimization if needed.

#### Phase 5: Code Review

Skip if Phase 4 produced no code files (only docs/config). Note the skip.

Spawn three reviewers **in parallel**:

```
Task:
  subagent_type: <code-review-minion | lucy | margo>
  description: "Phase 5 code review"
  model: <sonnet for code-review-minion, opus for lucy/margo>
  prompt: |
    You are reviewing code produced during an orchestrated execution.

    ## Changed Files
    <list files created/modified during Phase 4, from the change ledger>

    ## Execution Context
    Read scratch files for context: nefario/scratch/{slug}/phase3-synthesis.md

    ## Your Review Focus
    <code-review-minion: code quality, correctness, bug patterns,
     cross-agent integration, complexity, DRY, security implementation
     (hardcoded secrets, injection vectors, auth/authz, crypto, CVEs)>
    <lucy: convention adherence, CLAUDE.md compliance, intent drift>
    <margo: over-engineering, YAGNI, dependency bloat>

    ## Instructions
    Review the actual code files listed above. Return verdict:

    VERDICT: APPROVE | ADVISE | BLOCK
    FINDINGS:
    - [BLOCK|ADVISE|NIT] <file>:<line-range> -- <description>
      AGENT: <producing-agent>
      FIX: <specific fix>

    Write findings to: nefario/scratch/{slug}/phase5-{your-name}.md
```

**Process verdicts**:
- All APPROVE/ADVISE: write ADVISE findings to scratch. Proceed to Phase 6.
- Any BLOCK: group findings by producing agent. Spawn fix tasks with the
  specific findings. Re-review changed files only. Cap at 2 rounds.
- Security-severity BLOCKs (injection, auth bypass, secret exposure, crypto):
  surface to user before auto-fix (SHOW: max 5-line escalation brief).
- After 2 rounds unresolved: escalate to user with structured brief:
  ```
  VERIFICATION ISSUE: <title>
  Phase: Code Review | Agent: <reviewer>
  Finding: <one-sentence description>
  Producing agent: <who wrote the code> | File: <path>
  Auto-fix attempts: 2 (unsuccessful)
  Options: fix manually / accept as-is / skip remaining verification
  ```

#### Phase 6: Test Execution

Runs after Phase 5 (or after Phase 4 if Phase 5 was skipped). Skip if no
tests exist AND Phase 4 did not produce tests. Note the skip.

1. **Test discovery** (4-step sequence):
   - Check for test commands: `package.json` scripts, `Makefile` targets,
     `pyproject.toml` pytest config
   - Check CI config: `.github/workflows/*.yml`, `.circleci/config.yml`
   - Scan for test files: `**/*.test.{ts,js}`, `**/*.spec.*`, `**/test_*.py`,
     `**/*_test.go`, `tests/`, `__tests__/`
   - Check framework config: `vitest.config.*`, `jest.config.*`, `pytest.ini`

2. **Baseline comparison**: Compare against baseline captured at Phase 4
   start (if available). New failures = blocking. Pre-existing = non-blocking.
   Heuristic fallback: if failing test was not modified in Phase 4, treat as
   likely pre-existing.

3. **Layered execution**: lint/type-check -> unit tests -> integration/E2E
   (skip integration/E2E if prerequisites unavailable).

4. **Process results**:
   - All pass: write summary to scratch. Proceed to Phase 7/8.
   - New failures: route to producing agent for fix (infrastructure issues
     to test-minion instead). Cap at 2 rounds. Escalate if unresolved.
   - Pre-existing failures: document as non-blocking ADVISE.
   - No test infrastructure found: ADVISE with note, not a silent pass.

5. Write output to: `nefario/scratch/{slug}/phase6-test-results.md`

#### Phase 7: Deployment (Conditional)

Skip unless user opted in at plan approval. This is a separate opt-in,
not part of the default flow.

1. Run deployment command (e.g., `./install.sh`). Report pass/fail.
2. If command fails: BLOCK and escalate to user.
3. Write output to: `nefario/scratch/{slug}/phase7-deployment.md`

#### Phase 8: Documentation (Conditional)

1. **Generate checklist** from execution outcomes:

   | Outcome | Action | Owner |
   |---------|--------|-------|
   | New API endpoints | API reference, OpenAPI prose | software-docs-minion |
   | Architecture changed | C4 diagrams, component docs | software-docs-minion |
   | Gate-approved decision | ADR | software-docs-minion |
   | New user-facing feature | Getting-started / how-to | user-docs-minion |
   | New CLI command/flag | Usage docs | user-docs-minion |
   | User-visible bug fix | Release notes | user-docs-minion |
   | README not updated | README review | software-docs + product-marketing |
   | New project (git init) | Full README (blocking) | software-docs + product-marketing |
   | Breaking change | Migration guide | user-docs-minion |
   | Config changed | Config reference | software-docs-minion |

   Write checklist to: `nefario/scratch/{slug}/phase8-checklist.md`

2. If checklist is empty, skip entirely.

3. **Sub-step 8a** (parallel): spawn software-docs-minion + user-docs-minion
   with their respective checklist items and paths to execution artifacts.

4. **Sub-step 8b** (sequential, after 8a): if checklist includes README or
   user-facing docs, spawn product-marketing-minion to review. Otherwise skip.

5. Non-blocking by default. Exception: new project requires README before PR.

6. Write output to: `nefario/scratch/{slug}/phase8-software-docs.md`,
   `phase8-user-docs.md`, `phase8-marketing-review.md`

### Wrap-up

7. **Review all deliverables** and consolidate verification results.

   Build the **Verification summary** from Phase 5-8 outcomes:
   - Default (all passed): "Verification: all checks passed."
   - With auto-fixes: "Verification: 2 code review findings auto-fixed, all tests pass, docs updated (3 files)."
   - Partial skip: "Verification: code review passed, tests skipped (none found), docs updated (2 files)."
   Priority: lead with pass/fail, then exceptions, then per-phase detail.

8. **Auto-commit remaining changes** — silently commit any uncommitted files
   from the change ledger before generating the report. Print the informational
   commit line (`Committed N files: ...`).

9. **Verify and report** — follow the wrap-up sequence documented in the
   "Report Generation" section below (review deliverables, write report,
   update index, present to user, shutdown teammates, final status).

10. **PR creation** — after the report is committed, if on a feature branch,
    offer to create a pull request:

    ```
    Create PR for nefario/<slug>? (Y/n)
    ```

    If approved: `git push -u origin <branch>` then create the PR.
    Use the report body as the PR description. Write the stripped body to a
    temp file to avoid shell expansion issues:
    ```sh
    body_file=$(mktemp)
    tail -n +2 "$report_file" | sed '1,/^---$/d' > "$body_file"
    gh pr create --title "$pr_title" --body-file "$body_file"
    rm -f "$body_file"
    ```
    The `--title` comes from the frontmatter `task` field. If the temp file
    is empty or starts with `---`, warn and fall back to the executive summary only.
    If `gh` is unavailable, print the manual push command instead.
    See [docs/commit-workflow.md](../docs/commit-workflow.md) for details.

11. **Return to main** — after PR creation (or if declined):
    `git checkout main && git pull --rebase`. Include branch name in
    final summary.

### Troubleshooting: Orchestrator Not Progressing

If the main session seems stuck after agents complete (not reacting to
completion messages), this may be a Claude Code message delivery timing
issue, especially in TMUX mode. Workarounds:

- Tell the main session "check task status" or "agents are done" to
  nudge it forward — it will call TaskList and catch up.
- The monitoring instructions above are designed to minimize this, but
  if it persists, it's a platform limitation, not a configuration issue.

## Report Generation

After completing the orchestration, generate an execution report to document
the process, decisions, and outcomes. The calling session (main Claude Code
session executing this skill) generates the report, not nefario as a subagent.

### Data Accumulation

Phase data is tracked in two places:
- **Scratch files** (on disk): Full phase outputs for reference and recovery.
  See Scratch File Convention above.
- **Session context** (in memory): Compact summaries for report generation.
  The items below describe what to retain in session context at each boundary.

Track data at phase boundaries:

**After Phase 1 (Meta-plan)**:
- Timestamp
- Task description (one-line summary)
- Specialists identified
- Generate filename slug: kebab-case, lowercase, max 40 chars from task
  description. Strip articles (a/an/the). Only alphanumeric and hyphens.
  No path separators or special characters.

**After Phase 2 (Specialist Planning)**:
- Which specialists contributed
- Key recommendation from each (1 sentence)

**After Phase 3 (Synthesis)**:
- Task count
- Gate count
- Conflict resolutions (if any)

**After Phase 3.5 (Architecture Review)**:
- Reviewers consulted
- Verdicts (APPROVE/ADVISE/BLOCK)
- Revision rounds (if any)

**After Phase 4 (Execution)**:
- Per-task outcomes
- Files created or modified
- Gate decisions and responses
- Gate decision briefs: for each gate presented, retain the full decision brief
  (rationale bullets, rejected alternatives, confidence level, and outcome) in
  session context. These populate the enriched gate briefs in the report's
  Decisions and Execution sections.

**After Phase 5-8 (Post-Execution)**:
- Code review findings count (BLOCK/ADVISE/NIT) and resolution status
- Test results (pass/fail/skip counts, coverage assessment)
- Deployment status (pass/fail/skipped)
- Documentation files created/updated (count and paths)

**At Wrap-up**:
- Outstanding items
- Approximate total duration

**Fallback for compacted summaries**: If inline summaries or gate decision
briefs were lost to compaction, read scratch files from
`nefario/scratch/{slug}/phase2-*.md` and `nefario/scratch/{slug}/phase3.5-*.md`
at wrap-up to reconstruct agent contribution summaries and gate briefs for
the report.

### Report Template

See `docs/history/nefario-reports/TEMPLATE.md` for the complete report format, including YAML frontmatter schema, body structure, file naming convention, and index update instructions.

### Incremental Writing

For long-running orchestrations, write a partial report after Phase 3
(synthesis). Include available data and mark sections as "In Progress".
Overwrite with the complete report at wrap-up.

### Wrap-up Sequence (MANDATORY)

When all tasks are complete, you MUST execute every step below. The execution
report is not optional — it is as mandatory as the synthesis phase. Do not
skip it, do not defer it, do not stop before it is written.

1. Review all deliverables
2. **Verification summary** — consolidate Phase 5-8 outcomes into a single
   block for the report and user summary. Format:
   - Default: "Verification: all checks passed."
   - With fixes: "Verification: N code review findings auto-fixed, all tests pass, docs updated (M files)."
   - Skipped: "Verification: skipped (--skip-post)."
3. Auto-commit remaining changes (silent, informational line only)
4. **Write execution report** to `docs/history/nefario-reports/<YYYY-MM-DD>-<HHMMSS>-<slug>.md`
   — capture HHMMSS as the current local time (24-hour, zero-padded) at the
     moment of writing the report
   — follow the template at `docs/history/nefario-reports/TEMPLATE.md`
   — include a Verification section with Phase 5-8 outcomes
5. **Regenerate index** by running `docs/history/nefario-reports/build-index.sh`
6. Commit the report (auto-commit, no prompt needed)
7. Offer PR creation if on a feature branch
8. Return to main: `git checkout main && git pull --rebase`
9. Present report path, PR URL, branch name, and Verification summary to user
10. Send shutdown_request to teammates
11. TeamDelete
12. Report final status to user

